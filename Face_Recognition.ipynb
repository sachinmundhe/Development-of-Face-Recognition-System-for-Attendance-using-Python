{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "045d1854",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h1> Project Title: Development of Face Recognition System for Attendance using Python</h1>\n",
    "\n",
    "<h2>Submitted by: Sachin Maruti Mundhe</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b82e518",
   "metadata": {},
   "source": [
    "# <font color= coral>Objective:\n",
    "## Develop a system that uses face recognition to automate attendance logging in real-time.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b28f5f",
   "metadata": {},
   "source": [
    "## Step 1: Set Up the Environment\n",
    "Start by setting up the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe91b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install face_recognition\n",
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3318a8",
   "metadata": {},
   "source": [
    "### A. Face Detection using OpenCV\n",
    "This code captures a live video feed and detects faces in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e3438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Converting the frame to grayscale (for better performance in face detection)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use OpenCV's pre-trained face detector\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Draw rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "    # Exit the loop with 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64490c0f",
   "metadata": {},
   "source": [
    "### B. Face Recognition using face_recognition library\n",
    "This code recognizes faces and logs attendance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0bb22",
   "metadata": {},
   "source": [
    "## Step 2: Load Images for Recognition\n",
    "First, load and encode images of people whose attendance needs to be recorded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ad035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of loading and encoding images\n",
    "def load_and_encode_image(image_path):\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    image_encoding = face_recognition.face_encodings(image)[0]\n",
    "    return image_encoding\n",
    "\n",
    "# Loading my reference images (known faces)\n",
    "known_face_encodings = [\n",
    "    load_and_encode_image(r\"C:\\Users\\Sachin's World\\Documents\\Research_School\\Mine_Face_Recognition\\Training_images\\Sachin.jpg\"),  # Path to your image\n",
    "    load_and_encode_image(r\"C:\\Users\\Sachin's World\\Documents\\Research_School\\Mine_Face_Recognition\\Training_images\\Modiji.png\"),\n",
    "]\n",
    "known_face_names = ['Sachin', 'Modiji']  # Names of the individuals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5436e46e",
   "metadata": {},
   "source": [
    "## Step 3: Start Video Stream and Detect Faces\n",
    "I have implemented the real-time face detection using OpenCV. By Using the webcam feed to capture video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc0779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the video stream from webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Initializing variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "\n",
    "while True:\n",
    "    # Capturing a single frame\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    # Resizing frame to improve speed\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    \n",
    "    # Converting the image from BGR (OpenCV default) to RGB\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "    \n",
    "    # Processing every other frame for speed improvement\n",
    "    if process_this_frame:\n",
    "        # Finding face locations and face encodings in the current frame\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "        \n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "            \n",
    "            # If a match is found in known_face_encodings\n",
    "            if True in matches:\n",
    "                first_match_index = matches.index(True)\n",
    "                name = known_face_names[first_match_index]\n",
    "            \n",
    "            face_names.append(name)\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "    # Displaying the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scaling back up since the frame was resized\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Drawing a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Labeling the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Displaying the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Breaking from loop with 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Releasing the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284cbbd1",
   "metadata": {},
   "source": [
    "## Step 4: Marking Attendance in CSV File\n",
    "When a face is recognized, I have loged the attendance with the current date and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcccb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created a function to mark attendance\n",
    "def mark_attendance(name):\n",
    "    # Reading the existing attendance CSV (or create a new one)\n",
    "    try:\n",
    "        attendance_data = pd.read_csv('attendance_logs.csv')\n",
    "    except FileNotFoundError:\n",
    "        attendance_data = pd.DataFrame(columns=['Name', 'Date', 'Time'])\n",
    "\n",
    "    now = datetime.now()\n",
    "    date_str = now.strftime('%Y-%m-%d')\n",
    "    time_str = now.strftime('%H:%M:%S')\n",
    "\n",
    "    # Checking if the person is already marked for the day\n",
    "    if not ((attendance_data['Name'] == name) & (attendance_data['Date'] == date_str)).any():\n",
    "        attendance_data = attendance_data.append({'Name': name, 'Date': date_str, 'Time': time_str}, ignore_index=True)\n",
    "        attendance_data.to_csv('attendance.csv', index=False)\n",
    "        print(f'{name} marked as present at {time_str}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82abccd4",
   "metadata": {},
   "source": [
    "I have Added this functionality into the video stream loop to log attendance when a face is recognized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b30cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within the face recognition loop, mark attendance\n",
    "for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "    # Mark attendance only if face is recognized\n",
    "    if name != \"Unknown\":\n",
    "        mark_attendance(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbb9e05",
   "metadata": {},
   "source": [
    "## Step 5: Report Generation\n",
    "Exported the attendance record as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the attendance data and display it\n",
    "attendance_data = pd.read_csv('attendance_logs.csv')\n",
    "print(attendance_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f19a8b1",
   "metadata": {},
   "source": [
    "# Step 6: Optional - Building a Face Recognition Using Flask\n",
    "I have built in depth a  Flask UI :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ad6fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install flask opencv-python-headless pandas face-recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922543e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template\n",
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# Initializing Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# List of known faces and corresponding names\n",
    "known_face_encodings = []\n",
    "known_face_names = [\"Sachin\", \"Modiji\"]  # Add any other names if needed\n",
    "\n",
    "# Loading reference images and encode them\n",
    "def load_and_encode_image(image_path):\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    image_encoding = face_recognition.face_encodings(image)[0]\n",
    "    return image_encoding\n",
    "\n",
    "# Replace 'sachin.jpg' and 'modiji.jpg' with actual image paths\n",
    "known_face_encodings = [\n",
    "    load_and_encode_image(\"C:\\Users\\Sachin's World\\Documents\\Research_School\\Mine_Face_Recognition\\Training_images\\Sachin.jpg\"),\n",
    "    load_and_encode_image(\"C:\\Users\\Sachin's World\\Documents\\Research_School\\Mine_Face_Recognition\\Training_images\\Modiji.png\")\n",
    "]\n",
    "\n",
    "# Initialize attendance DataFrame\n",
    "attendance_data = pd.DataFrame(columns=['Name', 'Date', 'Time'])\n",
    "\n",
    "# Marking attendance\n",
    "def mark_attendance(name):\n",
    "    global attendance_data\n",
    "    now = datetime.now()\n",
    "    date_str = now.strftime('%Y-%m-%d')\n",
    "    time_str = now.strftime('%H:%M:%S')\n",
    "    \n",
    "    # Check if the person is already marked for today\n",
    "    if not ((attendance_data['Name'] == name) & (attendance_data['Date'] == date_str)).any():\n",
    "        attendance_data = pd.concat([attendance_data, pd.DataFrame({'Name': [name], 'Date': [date_str], 'Time': [time_str]})], ignore_index=True)\n",
    "        attendance_data.to_csv('attendance_logs.csv', index=False)\n",
    "        print(f'{name} marked as present at {time_str}')\n",
    "\n",
    "# Route for the homepage that shows the attendance logs\n",
    "@app.route('/')\n",
    "def home():\n",
    "    # Load attendance data from CSV\n",
    "    data = pd.read_csv('attendance_logs.csv')\n",
    "    return render_template('attendance_logs.html', tables=[data.to_html(classes='table table-striped')], titles=['Attendance Logs'])\n",
    "\n",
    "# Route to capture and process face recognition\n",
    "@app.route('/recognize')\n",
    "def recognize():\n",
    "    # Open webcam and capture video\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resizing the frame for faster processing\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "        \n",
    "        # Detecting faces in the frame\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "        \n",
    "        for face_encoding in face_encodings:\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "            \n",
    "            if True in matches:\n",
    "                first_match_index = matches.index(True)\n",
    "                name = known_face_names[first_match_index]\n",
    "                mark_attendance(name)\n",
    "        \n",
    "        # Displaying the frame with face detection (optional)\n",
    "        for (top, right, bottom, left) in face_locations:\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "            \n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "        # Showing the result\n",
    "        cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "        # Breaking the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Releasing webcam and close window\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return \"Face recognition complete. Check attendance logs.\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba49f84",
   "metadata": {},
   "source": [
    "## Explanation of the Code:\n",
    "\n",
    "### 1 Flask Setup:\n",
    "\n",
    "The Flask app serves two routes:\n",
    "/: Displays the attendance logs.\n",
    "/recognize: Triggers face recognition using the webcam.\n",
    "\n",
    "### 2 Face Recognition:\n",
    "I have loaded and encode reference images of \"Sachin\" and \"Modiji\" using the face_recognition library.\n",
    "The recognize route captures live video from the webcam, detects faces, and compares them to the reference images.\n",
    "\n",
    "### 3 Mark Attendance:\n",
    "The mark_attendance function records the recognized person's name, date, and time in a CSV file (attendance_logs.csv).\n",
    "\n",
    "### 4 Rendering Attendance Logs:\n",
    "\n",
    "The / route reads from the attendance_logs.csv and renders the data into an HTML table using the pandas.to_html() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8d2b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
